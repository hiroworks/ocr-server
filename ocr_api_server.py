# ocr_api_server.py

# --- ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®èª­ã¿è¾¼ã¿ ---
import os
import cv2                                      # OpenCVã€‚ç”»åƒã‚’èª­ã¿è¾¼ã¿åŠ å·¥
import re
import json
import time
import numpy as np
import threading
import requests
import sqlite3
from flask import Flask, request, jsonify       # APIã‚µãƒ¼ãƒãƒ¼ã‚’å‹•ã‹ã™ãŸã‚ã®Webãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯
from pyzbar import pyzbar                       # ãƒãƒ¼ã‚³ãƒ¼ãƒ‰èª­ã¿å–ã‚Šç”¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
from paddleocr import PaddleOCR                 # æ–‡å­—èªè­˜ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªï¼ˆæ—¥æœ¬èªå¯¾å¿œï¼‰
from dotenv import load_dotenv                  # ç§˜å¯†æƒ…å ±ï¼ˆAPIã‚­ãƒ¼ãªã©ï¼‰ã®å®‰å…¨ãªèª­ã¿è¾¼ã¿
from flask_cors import CORS                     # ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã¨ã®é€šä¿¡ã‚’è¨±å¯
from geopy.distance import geodesic             # è·é›¢è¨ˆç®—ï¼ˆãŠåº—ãŒè¿‘ã„ã‹åˆ¤å®šï¼‰

# --- ç’°å¢ƒå¤‰æ•°ã¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæº–å‚™ ---
load_dotenv()
UPLOAD_FOLDER = './uploads'
OUTPUT_FOLDER = './outputs'
os.makedirs(UPLOAD_FOLDER, exist_ok=True)
os.makedirs(OUTPUT_FOLDER, exist_ok=True)

# --- .env èª­ã¿è¾¼ã¿ ---
load_dotenv()
RAKUTEN_APP_ID = os.getenv("RAKUTEN_APP_ID")

# ã‚«ãƒ¬ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®å–å¾—
cwd = os.getcwd()
print("=== ã‚«ãƒ¬ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª ===")
print(cwd)
print("=== /app ã®å†…å®¹ ===")
print(os.listdir("/app"))
print("=== det ===")
print(os.listdir("/app/ch_PP-OCRv3_det_infer"))
print(os.listdir("./ch_PP-OCRv3_det_infer"))
print("=== rec ===")
print(os.listdir("/app/japan_PP-OCRv3_rec_infer"))
print(os.listdir("./japan_PP-OCRv3_rec_infer"))
print("=== cls ===")
print(os.listdir("/app/ch_ppocr_mobile_v2.0_cls_infer"))
print(os.listdir("./ch_ppocr_mobile_v2.0_cls_infer"))
# ã‚«ãƒ¬ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä¸­èº«ã‚’ä¸€è¦§è¡¨ç¤º
print("=== ã‚«ãƒ¬ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®å†…å®¹ ===")
for item in os.listdir(cwd):
    print(item)


# --- DB(SQLite)æº–å‚™ ---
# SQLite DBåˆæœŸåŒ–
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
DB_PATH = os.path.join(BASE_DIR, "price_records.db")
conn = sqlite3.connect(DB_PATH, check_same_thread=False)
cursor = conn.cursor()

# ãƒ†ãƒ¼ãƒ–ãƒ«ãŒãªã‘ã‚Œã°ä½œæˆ
cursor.execute('''
    CREATE TABLE IF NOT EXISTS prices (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        product_name TEXT,
        price INTEGER,
        shop_name TEXT,
        lat REAL,
        lon REAL,
        jan  TEXT,
        image_url  TEXT,
        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
    )
''')
conn.commit()

# --- Flask åˆæœŸåŒ– å¤–éƒ¨ï¼ˆã‚¹ãƒãƒ›ã‚¢ãƒ—ãƒªï¼‰ã‹ã‚‰ã®é€šä¿¡ã‚’è¨±å¯ ---
t_flask = time.time()
app = Flask(__name__)
CORS(app)
app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER
print(f"FlaskåˆæœŸåŒ–æ™‚é–“ : {time.time() - t_flask:.2f}ç§’")
print("[DEBUG] ä½¿ç”¨ä¸­ã®DBãƒ•ã‚¡ã‚¤ãƒ«:", DB_PATH)


# === GeoJSON(åº—èˆ—ãƒ‡ãƒ¼ã‚¿)ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ï¼ˆãŠåº—ãƒ‡ãƒ¼ã‚¿ï¼‰ ===
geojson = {"type": "FeatureCollection", "features": []}
geojson_path = os.path.join("data", "shops.geojson")

try:
    with open(geojson_path, 'r', encoding='utf-8') as f:
        raw = json.load(f)

    if not raw.get("features") or not isinstance(raw["features"], list):
        raise ValueError("GeoJSONã®featuresãŒå­˜åœ¨ã—ãªã„ã‹ã€é…åˆ—ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")

    for index, feature in enumerate(raw["features"]):
        try:
            geometry = feature.get("geometry")
            if geometry["type"] != "Point":
                continue
            coords = geometry.get("coordinates")
            if not (isinstance(coords, list) and len(coords) == 2 and all(isinstance(c, (int, float)) for c in coords)):
                continue
            geojson["features"].append(feature)
        except Exception as inner_err:
            print(f"âš ï¸ Feature index {index} ã‚’ã‚¹ã‚­ãƒƒãƒ—: {inner_err}")

    print(f"âœ… æœ‰åŠ¹ãªPointå‹åº—èˆ—ãƒ‡ãƒ¼ã‚¿æ•°: {len(geojson['features'])}")

except Exception as e:
    print("âŒ shops.geojsonã®èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼:", e)


# --- OCR åˆæœŸåŒ– ---
print("ğŸ” OCRåˆæœŸåŒ–é–‹å§‹")
t_ocr_init = time.time()
ocr = PaddleOCR(
    det_model_dir='/app/ch_PP-OCRv3_det_infer',   # æ¤œå‡ºãƒ¢ãƒ‡ãƒ«ãƒ•ã‚©ãƒ«ãƒ€
    rec_model_dir='/app/japan_PP-OCRv3_rec_infer',   # èªè­˜ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚©ãƒ«ãƒ€
    cls_model_dir='/app/ch_ppocr_mobile_v2.0_cls_infer',   # è§’åº¦åˆ†é¡ãƒ¢ãƒ‡ãƒ«ï¼ˆuse_angle_cls=True ã®å ´åˆã§ã‚‚æŒ‡å®šå¯ï¼‰
    use_angle_cls=True,
    lang='japan'
)
#        ocr = PaddleOCR(use_angle_cls=True, lang='japan')
print("ğŸ” OCRåˆæœŸåŒ–å®Œäº†")
print(f"OCRåˆæœŸåŒ–æ™‚é–“: {time.time() - t_ocr_init:.2f}ç§’")


"""
# OCRåˆæœŸåŒ–
print("ğŸ” OCRåˆæœŸåŒ–é–‹å§‹")
t_ocr_init2 = time.time()
ocr = PaddleOCR(use_angle_cls=True, lang='japan')
print(f"OCRåˆæœŸåŒ–æ™‚é–“: {time.time() - t_ocr_init2:.2f}ç§’")
"""

# ãƒãƒ¼ã‚³ãƒ¼ãƒ‰å‡¦ç†ï¼ˆåˆ¥ã‚¹ãƒ¬ãƒƒãƒ‰ã§å³å®Ÿè¡Œï¼‰
def detect_barcode(img):
    print("ğŸ” ãƒãƒ¼ã‚³ãƒ¼ãƒ‰æ¤œå‡ºé–‹å§‹")
    try:
        barcodes = pyzbar.decode(img)
        for barcode in barcodes:
            if barcode.type == 'EAN13':
                jan_code = barcode.data.decode('utf-8')
                print(f"ğŸ“¦ JANã‚³ãƒ¼ãƒ‰æ¤œå‡º(by pyzbar): {jan_code}")
#                result = search_rakuten_product(jan_code, [])
                return jan_code  # â†JANã‚³ãƒ¼ãƒ‰èªè­˜çµæœã‚’è¿”ã™
#                return result  # â†æ¥½å¤©APIçµæœã‚’è¿”ã™
        print("ğŸ“¦ JANã‚³ãƒ¼ãƒ‰ã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚")
        return None
    except Exception as e:
        print(f"ãƒãƒ¼ã‚³ãƒ¼ãƒ‰æ¤œå‡ºã‚¨ãƒ©ãƒ¼: {e}")
        return None


"""
# --- OCR åˆæœŸåŒ– ---
print("ğŸ” OCRåˆæœŸåŒ–é–‹å§‹")
t_ocr_init = time.time()
ocr = PaddleOCR(use_angle_cls=True, lang='japan')
print(f"OCRåˆæœŸåŒ–æ™‚é–“: {time.time() - t_ocr_init:.2f}ç§’")
"""

# OCRå‡¦ç†ï¼ˆåˆ¥ã‚¹ãƒ¬ãƒƒãƒ‰ã§å³å®Ÿè¡Œï¼‰
def run_ocr_logic(filename):
    try:
        # --- OCR åˆæœŸåŒ– ---
#        print("ğŸ” OCRåˆæœŸåŒ–é–‹å§‹")
#        t_ocr_init = time.time()
#        ocr = PaddleOCR(
#            det_model_dir='/app/ch_PP-OCRv3_det_infer',   # æ¤œå‡ºãƒ¢ãƒ‡ãƒ«ãƒ•ã‚©ãƒ«ãƒ€
#            rec_model_dir='/app/ch_PP-OCRv3_rec_infer',   # èªè­˜ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚©ãƒ«ãƒ€
#            cls_model_dir='/app/ch_PP-OCRv3_cls_infer',   # è§’åº¦åˆ†é¡ãƒ¢ãƒ‡ãƒ«ï¼ˆuse_angle_cls=True ã®å ´åˆã§ã‚‚æŒ‡å®šå¯ï¼‰
#            use_angle_cls=True,
#            lang='japan'
#        )
#        ocr = PaddleOCR(use_angle_cls=True, lang='japan')
#        print(f"OCRåˆæœŸåŒ–æ™‚é–“: {time.time() - t_ocr_init:.2f}ç§’")

        img_path = os.path.join(UPLOAD_FOLDER, filename)
        output_dir = OUTPUT_FOLDER

        # ç”»åƒèª­ã¿è¾¼ã¿
        t_ocr_read = time.time()
        print("èª­ã¿è¾¼ã¿")  # ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒåˆ°é”ã—ãŸã“ã¨ã‚’ç¢ºèª
        image = cv2.imread(img_path)
        image_hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
        print(f"èª­ã¿è¾¼ã¿å®Œäº†: {time.time() - t_ocr_read:.2f}ç§’")

        # ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ« + ã‚·ãƒ£ãƒ¼ãƒ—åŒ–
        print("ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«ï¼†ã‚·ãƒ£ãƒ¼ãƒ—åŒ–")  # ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒåˆ°é”ã—ãŸã“ã¨ã‚’ç¢ºèª
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        sharpened = cv2.GaussianBlur(gray, (0, 0), 3)
        sharpened = cv2.addWeighted(gray, 1.5, sharpened, -0.5, 0)
        preprocessed_path = os.path.join(output_dir, "image_processed.jpg")
        cv2.imwrite(preprocessed_path, sharpened)

        # èµ¤è‰²ãƒã‚¹ã‚¯
        def create_red_mask(hsv_img):
            print("èµ¤è‰²ãƒã‚¹ã‚¯")  # ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒåˆ°é”ã—ãŸã“ã¨ã‚’ç¢ºèª
            lower_red1 = np.array([0, 70, 50])
            upper_red1 = np.array([10, 255, 255])
            lower_red2 = np.array([160, 70, 50])
            upper_red2 = np.array([180, 255, 255])
            mask1 = cv2.inRange(hsv_img, lower_red1, upper_red1)
            mask2 = cv2.inRange(hsv_img, lower_red2, upper_red2)
            return cv2.bitwise_or(mask1, mask2)

        # ä¾¡æ ¼æŠ½å‡ºç”¨ã®æ­£è¦è¡¨ç¾
        def split_text_price(text):
            print("ä¾¡æ ¼æŠ½å‡ºç”¨ã®æ­£è¦è¡¨ç¾")  # ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒåˆ°é”ã—ãŸã“ã¨ã‚’ç¢ºèª
            pattern = re.compile(r'\d{2,4}(?:\.\d{1,2})?å††')
            return pattern.findall(text)

        # ãƒãƒªã‚´ãƒ³åˆ†å‰²
        def split_polygon_horizontally(poly):
            print("ãƒãƒªã‚´ãƒ³åˆ†å‰²")  # ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒåˆ°é”ã—ãŸã“ã¨ã‚’ç¢ºèª
            poly = np.array(poly, dtype=np.float32)
            xs = poly[:, 0]
            sorted_xs = np.sort(xs)
            gaps = np.diff(sorted_xs)
            max_gap = np.max(gaps) if len(gaps) > 0 else 0
            img_w = image.shape[1]
            gap_threshold = img_w * 0.1
            if max_gap < gap_threshold:
                return [poly.astype(np.int32)]
            gap_idx = np.argmax(gaps)
            split_x = sorted_xs[gap_idx] + gaps[gap_idx] / 2
            left_points, right_points = [], []
            for p in poly:
                (left_points if p[0] <= split_x else right_points).append(p)
            def bounding_rect(points):
                points = np.array(points)
                x, y, w, h = cv2.boundingRect(points.astype(np.int32))
                return np.array([[x, y], [x + w, y], [x + w, y + h], [x, y + h]], dtype=np.int32)
            rects = []
            if len(left_points) >= 2:
                rects.append(bounding_rect(left_points))
            if len(right_points) >= 2:
                rects.append(bounding_rect(right_points))
            if not rects:
                rects.append(poly.astype(np.int32))
            return rects

        # OCRé–‹å§‹
        t_ocr_start = time.time()
        print("OCRé–‹å§‹")  # ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒåˆ°é”ã—ãŸã“ã¨ã‚’ç¢ºèª
        paddle_text_lines = []
        image_with_polys = image.copy()
        image_with_split_polys = image.copy()
        image_with_polys_on_preprocessed = cv2.cvtColor(sharpened.copy(), cv2.COLOR_GRAY2BGR)
        candidate_regions = []

#        t_ocr_init2 = time.time()
#        ocr = PaddleOCR(use_angle_cls=True, lang='japan')
#        print(f"OCRåˆæœŸåŒ–æ™‚é–“: {time.time() - t_ocr_init2:.2f}ç§’")
        result = ocr.predict(preprocessed_path)

        red_mask = create_red_mask(image_hsv)
        max_height = 1

        print("OCRå‡¦ç†ï¼‘")  # ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒåˆ°é”ã—ãŸã“ã¨ã‚’ç¢ºèª
        for ocr_result in result:
            if 'rec_polys' in ocr_result:
                for poly in ocr_result['rec_polys']:
                    height = np.linalg.norm(np.array(poly[0]) - np.array(poly[3]))
                    if height > max_height:
                        max_height = height

        print("OCRå‡¦ç†ï¼’")  # ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒåˆ°é”ã—ãŸã“ã¨ã‚’ç¢ºèª
        all_text_polys = []
        for ocr_result in result:
            if 'rec_polys' in ocr_result and 'rec_texts' in ocr_result and 'rec_scores' in ocr_result:
                polys = ocr_result['rec_polys']
                texts = ocr_result['rec_texts']
                scores = ocr_result['rec_scores']
                for poly, txt, score in zip(polys, texts, scores):
                    poly_np = np.array(poly, dtype=np.int32)
                    x, y, w, h = cv2.boundingRect(poly_np)
                    all_text_polys.append({'text': txt, 'poly': poly_np, 'bbox': (x, y, w, h)})
                    cv2.rectangle(image_with_polys, (x, y), (x + w, y + h), (0, 255, 0), 1)
                    cv2.rectangle(image_with_polys_on_preprocessed, (x, y), (x + w, y + h), (0, 255, 0), 1)
                    split_texts = split_text_price(txt)
                    split_polys = split_polygon_horizontally(poly_np)
                    for spoly in split_polys:
                        sx, sy, sw, sh = cv2.boundingRect(spoly)
                        cv2.rectangle(image_with_split_polys, (sx, sy), (sx + sw, sy + sh), (255, 0, 0), 2)
                    height_score = h / max_height
                    numeric_score = 1.0 if re.fullmatch(r"\d+", txt) else 0.0
                    mask = np.zeros(image.shape[:2], dtype=np.uint8)
                    cv2.fillPoly(mask, [poly_np], 255)
                    region = cv2.bitwise_and(image, image, mask=mask)
                    mean_color = cv2.mean(region, mask=mask)[:3]
                    is_red = mean_color[2] > 150 and mean_color[1] < 100 and mean_color[0] < 100
                    red_score = 1.0 if is_red else 0.0
                    nearby_score = 0.0
                    for other in all_text_polys:
                        if other['text'] in txt:
                            continue
                        ox, oy, ow, oh = other['bbox']
                        center_dist = np.linalg.norm(np.array([x + w/2, y + h/2]) - np.array([ox + ow/2, oy + oh/2]))
                        same_line = abs(y - oy) < h * 0.5
                        if center_dist < 150 and same_line and re.search(r"(å††|æœ¬ä½“|ç¨è¾¼|ä¾¡æ ¼)", other['text']):
                            nearby_score = 1.0
                            break
                    total_score = height_score * 3 + numeric_score * 3 + red_score * 2 + nearby_score * 2
                    candidate_regions.append({
                        'score': total_score,
                        'text': txt,
                        'poly': poly_np,
                        'bbox': (x, y, w, h)
                    })
                    paddle_text_lines.append(txt)

        # --- æ§‹é€ åŒ–æƒ…å ±ã®æŠ½å‡º ---
        def extract_structured_info(lines, fallback_base_price=""):
            print("æ§‹é€ åŒ–æƒ…å ±ã®æŠ½å‡º")  # ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒåˆ°é”ã—ãŸã“ã¨ã‚’ç¢ºèª
            text_block = "\n".join(lines)
            product_name = ""
            for line in lines:
                if re.match(r"^[\d\s\W_]+$", line):
                    continue
                if len(line) >= 5 and not re.search(r"\d", line):
                    product_name = line
                    break
            jan_match = re.search(r"\b(\d{13})\b", text_block)
            jan_code = jan_match.group(1) if jan_match else ""
            base_price_match = re.search(r"(\d{2,4})\s*å††\s*[\n ]*æœ¬ä½“", text_block)
            base_price = base_price_match.group(1) if base_price_match else fallback_base_price
            tax_price_match = re.search(r"(\d{2,4}(?:\.\d{1,2})?)\s*å††", text_block)
            tax_price = tax_price_match.group(1) if tax_price_match else ""
            if tax_price == base_price:
                tax_price = ""
            expiry_match = re.search(r"\b(\d{1,2}/\d{1,2})\b", text_block)
            expiry = expiry_match.group(1) if expiry_match else ""
            return {
                "å•†å“å": product_name,
                "JANã‚³ãƒ¼ãƒ‰": jan_code,
                "æœ¬ä½“ä¾¡æ ¼": base_price,
                "ç¨è¾¼ä¾¡æ ¼": tax_price,
                "ç‰¹å£²æœŸé™": expiry
            }

        # --- æœ¬ä½“ä¾¡æ ¼ã®è£œå®Œï¼ˆå†OCRã§é«˜ã‚¹ã‚³ã‚¢ãªæ•°å­—ï¼‰ ---
        print("æœ¬ä½“ä¾¡æ ¼ã®è£œå®Œ")  # ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒåˆ°é”ã—ãŸã“ã¨ã‚’ç¢ºèª
        best_numeric = sorted(
            [c for c in candidate_regions if re.fullmatch(r"\d{2,4}", c['text'])],
            key=lambda x: -x['score']
        )
        fallback_base_price = best_numeric[0]['text'] if best_numeric else ""

        # --- æ§‹é€ åŒ–å‡ºåŠ›ãƒ»ä¿å­˜ ---
        print("æ§‹é€ åŒ–å‡ºåŠ›ãƒ»ä¿å­˜")  # ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒåˆ°é”ã—ãŸã“ã¨ã‚’ç¢ºèª
        structured = extract_structured_info(paddle_text_lines, fallback_base_price)
        json_path = os.path.join(output_dir, "structured_output.json")
        with open(json_path, "w", encoding="utf-8") as f:
            json.dump(structured, f, ensure_ascii=False, indent=2)
        print(json.dumps(structured, ensure_ascii=False, indent=2))

        print(f"OCRèªè­˜å®Œäº†: {time.time() - t_ocr_start:.2f}ç§’")
        print("èªè­˜çµæœ(by PaddleOCR)",(structured))
        print("JANã‚³ãƒ¼ãƒ‰(by PaddleOCR)",(structured.get("JANã‚³ãƒ¼ãƒ‰")))
        print("å•†å“å(by PaddleOCR)", structured.get("å•†å“å", []))

#        search_rakuten_product(structured.get("JANã‚³ãƒ¼ãƒ‰"), structured.get("å•†å“å", []))



        # --- OCRå‡ºåŠ›çµæœã®è¡¨ç¤ºï¼ˆå¾“æ¥å½¢å¼ï¼‰ ---
        print("\nâ‘¢ å†OCRçµæœï¼ˆ1/10ã‚µã‚¤ã‚ºç”»åƒãƒ»ç™½èƒŒæ™¯ï¼‰:")
    
        if best_numeric:
            print(f"  '{best_numeric[0]['text']}' (score: {best_numeric[0]['score']:.2f})")
        else:
            print("  (ãªã—)")
        print("\nğŸ”¤ OCRã§æ¤œå‡ºã•ã‚ŒãŸå…¨æ–‡ãƒ†ã‚­ã‚¹ãƒˆ:")
        for line in paddle_text_lines:
            print("   ", line)

        # ãƒ‡ãƒãƒƒã‚°ç”»åƒä¿å­˜
        cv2.imwrite(os.path.join(output_dir, "debug_poly_drawn.jpg"), image_with_polys)
        cv2.imwrite(os.path.join(output_dir, "debug_split_poly_drawn.jpg"), image_with_split_polys)
        cv2.imwrite(os.path.join(output_dir, "debug_poly_drawn_preprocessed.jpg"), image_with_polys_on_preprocessed)
        cv2.imwrite(os.path.join(output_dir, "gray.jpg"), gray)

        return structured

##        return jsonify(structured)
        # --- æ¥½å¤©å•†å“æ¤œç´¢ ---
#       result_data = search_rakuten_product(
#            structured.get("JANã‚³ãƒ¼ãƒ‰"),
#            structured.get("å•†å“å", [])
#       )
##        result_data = search_rakuten_product(jan_code, product_name)


#        print("âœ… JSONè¿”å´:", json.dumps({
#            "source": "ocr",
#            structured
#            "structured": structured,
#            "result": result_data or {"æ¤œç´¢çµæœ": [], "æ¤œç´¢ç¨®åˆ¥": "ãªã—", "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰": ""}    # æ¥½å¤©æ¤œç´¢çµæœ
#        }, ensure_ascii=False, indent=2))
#        return {
#            "source": "ocr",
#            structured
#            "structured": structured,
#            "result": result_data    # æ¥½å¤©æ¤œç´¢çµæœ
#        }
  
#        return jsonify({
#            "source": "ocr",
#            "structured": structured,
#            "result": result_data
#        })


    except Exception as e:
        return jsonify({'error': str(e)}), 500





# --- æ¥ç¶šç¢ºèªç”¨ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ ---
@app.route('/', methods=['GET'])
def index():
    return 'OCR API Server is running.'


# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã§OCRçµæœã‚’ä¿æŒï¼ˆç°¡æ˜“ãªä¾‹ï¼‰
ocr_cache = {}




# --- ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å‡¦ç†ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ ---
# --- ãƒãƒ¼ã‚³ãƒ¼ãƒ‰èªè­˜ã€OCRèªè­˜ã€æ¥½å¤©APIæ¤œç´¢ã®å‡¦ç† ---
t_upload = time.time()
from shutil import copyfile  # â† ãƒ•ã‚¡ã‚¤ãƒ«ã‚³ãƒ”ãƒ¼ã«ä½¿ã†ã€€             â– â– â–  ã“ã‚Œã ã‘å¾Œã§æ¶ˆã™ï¼ â– â– â– â– 
@app.route('/upload', methods=['POST'])
def upload_image():
    print("UPLOADå®Ÿè¡Œ")  # ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒåˆ°é”ã—ãŸã“ã¨ã‚’ç¢ºèª
    if 'file' not in request.files:
        return jsonify({'error': 'No file provided'}), 400


# ğŸ‘‡ å›ºå®šãƒ•ã‚¡ã‚¤ãƒ«åã«ã™ã‚Šæ›¿ãˆï¼ˆä¾‹: sample.jpgï¼‰ã€€                   â– â– â–  ã“ã“ã‹ã‚‰copyfileã¾ã§å¾Œã§æ¶ˆã™ï¼ â– â– â– â– 
    filename = 'sample.jpg'
    filepath = os.path.join('sample.jpg')  # sample.jpgã®ä¿å­˜å ´æ‰€
    dest_path = os.path.join(app.config['UPLOAD_FOLDER'], filename)
    # ğŸ‘‡ sample.jpg ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å…ˆã«ã‚³ãƒ”ãƒ¼ï¼ˆã™ã‚Šæ›¿ãˆï¼‰
    copyfile(filepath, dest_path)
    print(f"ç”»åƒä¿å­˜å®Œäº†: {filepath}")
    print(f"ç”»åƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ™‚é–“: {time.time() - t_upload:.2f}ç§’")


#    file = request.files['file']
#    filename = file.filename
#    filepath = os.path.join(app.config['UPLOAD_FOLDER'], filename)
#    file.save(filepath)


    # ğŸ” ãƒãƒ¼ã‚³ãƒ¼ãƒ‰ã‚¹ãƒ¬ãƒƒãƒ‰ã‚’é–‹å§‹
    t_barcode_start = time.time()
    image = cv2.imread(filepath)

    # --- â‘  ãƒãƒ¼ã‚³ãƒ¼ãƒ‰èªè­˜ï¼ˆå…ˆè¡Œå®Ÿè¡Œï¼‰
    t_barcode_start = time.time()
    barcode_result = detect_barcode(image)
    print(f"ğŸ“¦ ãƒãƒ¼ã‚³ãƒ¼ãƒ‰èªè­˜çµæœ: {barcode_result}")
    print(f"ğŸ“¦ ãƒãƒ¼ã‚³ãƒ¼ãƒ‰èªè­˜: {time.time() - t_barcode_start:.2f}ç§’")

    # --- â‘¢ æ¥½å¤©APIæ¤œç´¢ï¼ˆJANã‚³ãƒ¼ãƒ‰å„ªå…ˆã€ãªã‘ã‚Œã°å•†å“åã§ï¼‰
#    rakuten_result = search_rakuten_product(
#       barcode_result,
#        []
#   )

    # --- JANã‚³ãƒ¼ãƒ‰ã«ã‚ˆã‚‹æ¥½å¤©æ¤œç´¢
    if barcode_result:
        rakuten_result = search_rakuten_product(
            barcode_result,
#            barcode_result.get("ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰"),  # JANã‚³ãƒ¼ãƒ‰
            []  # å•†å“åã¯ç©º
        )



    # --- ãƒãƒ¼ã‚³ãƒ¼ãƒ‰èªè­˜ã€OCRèªè­˜ã€æ¥½å¤©APIæ¤œç´¢ã®çµæœã‚’è¿”ã™ ---
    if barcode_result:
        return jsonify({
            "filename": filename,
            "source": "barcode",
            "recognition": barcode_result,
            "rakuten": rakuten_result,
        })
    else:
        return jsonify({
            "filename": filename,
            "source": "barcode",
            "recognition": None
        })
    
    return jsonify({'message': 'Image uploaded successfully', 'filename': filename})



# --- ğŸ” æ¥½å¤©ã€Œå•†å“ä¾¡æ ¼ãƒŠãƒ“è£½å“æ¤œç´¢APIã€å‘¼ã³å‡ºã— ---
def search_rakuten_product(jan_code, product_names):
    endpoint = "https://app.rakuten.co.jp/services/api/Product/Search/20170426"
    headers = {
        "User-Agent": "ocr-app-client"
    }

    # å„ªå…ˆï¼šJANã‚³ãƒ¼ãƒ‰ã«ã‚ˆã‚‹æ¤œç´¢
    if jan_code:
        print(f"\nğŸ” JANã‚³ãƒ¼ãƒ‰ '{jan_code}' ã§æ¥½å¤©APIæ¤œç´¢ä¸­...")
        params = {
            "format": "json",
            "applicationId": RAKUTEN_APP_ID,
            "keyword": jan_code
        }
        try:
            res = requests.get(endpoint, params=params, headers=headers)
            res.raise_for_status()
            data = res.json()
            items = data.get("Products", [])
            if items:
                products = []
                print(f"âœ… JANã‚³ãƒ¼ãƒ‰æ¤œç´¢ã§ {len(items)} ä»¶ãƒ’ãƒƒãƒˆ")
                for item in items[:7]:
                    p = item["Product"]
                    print(f"- å•†å“å: {p['productName']}")
                    print(f"  ãƒ¡ãƒ¼ã‚«ãƒ¼: {p.get('makerName')}")
                    print(f"  ãƒ¡ãƒ¼ã‚«ãƒ¼æ­£å¼å: {p.get('makerNameFormal')}")
                    print(f"  ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³: {p.get('productCaption')}")
                    print(f"  å•†å“ç”»åƒ: {p.get('mediumImageUrl')}")
                    print(f"  æœ€å®‰ä¾¡æ ¼: {p.get('minPrice')}å††")
                    print(f"  URL: {p.get('productUrlMobile')}")

                    products.append({
                        "å•†å“å": p['productName'],
                        "ãƒ¡ãƒ¼ã‚«ãƒ¼": p.get('makerName'),
                        "ãƒ¡ãƒ¼ã‚«ãƒ¼æ­£å¼å": p.get('makerNameFormal'),
                        "ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³": p.get('productCaption'),
                        "å•†å“ç”»åƒ": p.get('mediumImageUrl'),
                        "æœ€å®‰ä¾¡æ ¼": p.get('minPrice'),
                        "URL": p.get('productUrlMobile')
                    })
                return {"æ¤œç´¢çµæœ": products, "æ¤œç´¢ç¨®åˆ¥": "JAN", "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰": jan_code}
            else:
                print("âŒ JANã‚³ãƒ¼ãƒ‰ã§ã¯è©²å½“å•†å“ãªã—")
                return None  # æ¤œç´¢å¤±æ•—    

        except Exception as e:
            print(f"APIã‚¨ãƒ©ãƒ¼ï¼ˆJANæ¤œç´¢ï¼‰: {e}")
            return None  # ğŸ‘ˆ æ˜ç¤º
        
    # æ¬¡ç‚¹ï¼šå•†å“åå€™è£œã§æ¤œç´¢
    if product_names:
        print(f"\nğŸ” å•†å“å '{product_names}' ã§æ¥½å¤©APIæ¤œç´¢ä¸­...")
        params = {
            "format": "json",
            "applicationId": RAKUTEN_APP_ID,
            "keyword": product_names
        }
    try:
        res = requests.get(endpoint, params=params, headers=headers)
        res.raise_for_status()
        data = res.json()
        items = data.get("Products", [])
        if items:
            print(f"âœ… '{product_names}' ã§ {len(items)} ä»¶ãƒ’ãƒƒãƒˆ")
            for item in items[:7]:
                p = item["Product"]
                print(f"- å•†å“å: {p['productName']}")
                print(f"  ãƒ¡ãƒ¼ã‚«ãƒ¼: {p.get('makerName')}")
                print(f"  ãƒ¡ãƒ¼ã‚«ãƒ¼æ­£å¼å: {p.get('makerNameFormal')}")
                print(f"  ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³: {p.get('productCaption')}")
                print(f"  å•†å“ç”»åƒ: {p.get('mediumImageUrl')}")
                print(f"  æœ€å®‰ä¾¡æ ¼: {p.get('minPrice')}å††")
                print(f"  URL: {p.get('productUrlMobile')}")

                products.append({
                    "å•†å“å": p['productName'],
                    "ãƒ¡ãƒ¼ã‚«ãƒ¼": p.get('makerName'),
                    "ãƒ¡ãƒ¼ã‚«ãƒ¼æ­£å¼å": p.get('makerNameFormal'),
                    "ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³": p.get('productCaption'),
                    "å•†å“ç”»åƒ": p.get('mediumImageUrl'),
                    "æœ€å®‰ä¾¡æ ¼": p.get('minPrice'),
                    "URL": p.get('productUrlMobile')
                })
            return {"æ¤œç´¢çµæœ": products, "æ¤œç´¢ç¨®åˆ¥": "JAN", "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰": jan_code}
        else:
            print("âŒ å•†å“åã§ã¯è©²å½“å•†å“ãªã—")
            return None  # æ¤œç´¢å¤±æ•—    
    except Exception as e:
        print(f"APIã‚¨ãƒ©ãƒ¼ï¼ˆå•†å“åæ¤œç´¢ï¼‰: {e}")
        print("âŒ ã™ã¹ã¦ã®æ¤œç´¢å€™è£œã§è©²å½“å•†å“ãªã—")
        return None  # ğŸ‘ˆ æ˜ç¤º
    


# --- OCRå‡¦ç†ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ ---
@app.route('/ocr', methods=['POST'])
def run_ocr():
    print("OCRãƒªã‚¯ã‚¨ã‚¹ãƒˆ")  # ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒåˆ°é”ã—ãŸã“ã¨ã‚’ç¢ºèª
    data = request.json
    if not data or 'filename' not in data:
        return jsonify({'error': 'Missing filename'}), 400
    filename = data['filename']
    ocr_result = run_ocr_logic(filename)  # âœ… OCRå‡¦ç†ã‚’å…±é€šé–¢æ•°ã§å®Ÿè¡Œ
    print(f"filename: {filename}")
    print(f"oceèªè­˜çµæœ1: {ocr_result}")

#    return jsonify(ocr_result)

    # --- æ¥½å¤©APIæ¤œç´¢
    # OCRèªè­˜å¾Œã®æ¥½å¤©APIæ¤œç´¢å‡¦ç†
    if ocr_result:
        # ã‚¿ãƒ—ãƒ«ã ã£ãŸå ´åˆã¯è¾æ›¸éƒ¨åˆ†ã‚’å–ã‚Šå‡ºã™
        if isinstance(ocr_result, tuple):
            ocr_result = ocr_result[0]
        if hasattr(ocr_result, "get_json"):
            ocr_result = ocr_result.get_json()
        print(f"oceèªè­˜çµæœ2: {ocr_result}")
        print("JANã‚³ãƒ¼ãƒ‰(by PaddleOCR)",(ocr_result.get("JANã‚³ãƒ¼ãƒ‰")))
        print("å•†å“å(by PaddleOCR)", (ocr_result.get("å•†å“å", [])))

        # å®‰å…¨ã«å–ã‚Šå‡ºã™
#        recognition = ocr_result.get("recognition", {})
        jan_code = ocr_result.get("JANã‚³ãƒ¼ãƒ‰")
        product_name = ocr_result.get("å•†å“å", [])
        print(f"JANã‚³ãƒ¼ãƒ‰: {jan_code}, å•†å“å: {product_name}")

        rakuten_result = search_rakuten_product(jan_code, product_name)
#            ocr_result.get("JANã‚³ãƒ¼ãƒ‰"),       # JANã‚³ãƒ¼ãƒ‰
#            ocr_result.get("å•†å“å"),          # å•†å“å
#        )

    # --- ãƒãƒ¼ã‚³ãƒ¼ãƒ‰èªè­˜ã€OCRèªè­˜ã€æ¥½å¤©APIæ¤œç´¢ã®çµæœã‚’è¿”ã™ ---
    if ocr_result:
        return jsonify({
            "filename": filename,
            "source": "ocr",
            "recognition": ocr_result,
            "rakuten": rakuten_result,
        })
    else:
        return jsonify({
            "filename": filename,
            "source": "ocr",
            "recognition": None
        })



# === è¿‘éš£åº—èˆ—æ¤œç´¢ ===
@app.route('/api/nearby-shops', methods=['POST'])
def nearby_shops():
    data = request.json
    print(f"{data}")
    latitude = data.get('lat')
    longitude = data.get('lon')
#   latitude = data.get('latitude')
#   longitude = data.get('longitude')
    print(f"ğŸ“¦ ç·¯åº¦: {latitude}")
    print(f"ğŸ“¦ çµŒåº¦: {longitude}")

    if not isinstance(latitude, (int, float)) or not isinstance(longitude, (int, float)):
        return jsonify({"error": "ç·¯åº¦ã¾ãŸã¯çµŒåº¦ãŒä¸æ­£ã§ã™ã€‚"}), 400

    if not (-90 <= latitude <= 90) or not (-180 <= longitude <= 180):
        return jsonify({"error": "ç·¯åº¦ã¾ãŸã¯çµŒåº¦ãŒä¸æ­£ã§ã™ã€‚"}), 400

    radius_km = 2.0
    nearby = []

    for index, feature in enumerate(geojson["features"]):
        try:
            lng, lat = feature["geometry"]["coordinates"]
#            print("feature latitude:",latitude)
#            print("feature longitude:", longitude)
#            print("feature lat:",lat)
#            print("feature lng:",lng)
            distance_km = geodesic((latitude, longitude), (lat, lng)).kilometers
            if distance_km <= radius_km:
                nearby.append({
                    "id": index,
                    "name": feature.get("properties", {}).get("name", "åç§°ä¸æ˜"),
                    "brand": feature.get("properties", {}).get("brand"),
                    "category": feature.get("properties", {}).get("shop"),
                    "coordinates": feature.get("geometry", {}).get("coordinates", []),
                    "distance_km": round(distance_km, 3)
                })
        except Exception as feature_err:
            print(f"âŒ Featureå‡¦ç†ã‚¨ãƒ©ãƒ¼ï¼ˆindex={index}ï¼‰: {feature_err}")

        # âœ… ç¾åœ¨åœ°ã«æœ€ã‚‚è¿‘ã„é †ï¼ˆï¼distance_km ã®æ˜‡é †ï¼‰ã«ä¸¦ã³æ›¿ãˆã‚‹
        nearby.sort(key=lambda s: s["distance_km"])

    print(f"ğŸ“¦ ãƒ’ãƒƒãƒˆåº—èˆ—æ•°: {len(nearby)}")
    if nearby:
        print("ğŸ” æœ€åˆã®åº—èˆ—ä¾‹:", json.dumps(nearby[0], ensure_ascii=False, indent=2))

    return jsonify({
        "count": len(nearby),
        "units": "kilometers",
        "origin": {"latitude": latitude, "longitude": longitude},
        "shops": nearby
    })



# === å€¤æœ­æƒ…å ±DBç™»éŒ² ===
@app.route('/api/register-price', methods=['POST'])
def register_price():

    cursor.execute("PRAGMA table_info(prices);")
    cols = cursor.fetchall()
    print("[DEBUG] ãƒ†ãƒ¼ãƒ–ãƒ«æ§‹é€ :", cols)

    data = request.json
    product_name = data.get('product_name')
    price = data.get('price')
    shop_name = data.get('shop_name')
    lat = data.get('lat')
    lon = data.get('lon')
    jan = data.get('jan')
    image_url = data.get('image_url')
    print(f"ğŸ“¦ register-priceã®å‡¦ç†ä¸­ãƒ»ãƒ»ãƒ»")
    print(f"{data}")
    if not all([product_name, price, shop_name, lat, lon, jan, image_url]):
        return jsonify({"error": "å…¨ã¦ã®é …ç›®ãŒå¿…è¦ã§ã™"}), 400

    try:
        cursor.execute('''
            INSERT INTO prices (product_name, price, shop_name, lat, lon, jan, image_url)
            VALUES (?, ?, ?, ?, ?, ?, ?)
        ''', (product_name, price, shop_name, lat, lon, jan, image_url))
        conn.commit()
        return jsonify({"message": "ä¾¡æ ¼æƒ…å ±ã‚’ç™»éŒ²ã—ã¾ã—ãŸ"}), 200
    except Exception as e:
        return jsonify({"error": str(e)}), 500



# === ä¾¡æ ¼ãƒ©ãƒ³ã‚­ãƒ³ã‚°ä½œæˆ ===
@app.route('/api/price-ranking', methods=['POST'])
def price_ranking():
    payload = request.json        # jan OR product_name,  lat, lon
    jan = payload.get("jan")
    pname = payload.get("product_name")
    lat0, lon0 = payload["lat"], payload["lon"]
    print(f"ğŸ“¦price-rankingã®å‡¦ç†ä¸­ãƒ»ãƒ»ãƒ»")
    print(f"{payload}")

    # åŒä¸€å•†å“ï¼šJAN ãŒã‚ã‚Œã°å„ªå…ˆã€ãªã‘ã‚Œã°å•†å“åã§ LIKE æ¤œç´¢
    if jan:
        cursor.execute("SELECT * FROM prices WHERE jan=?", (jan,))
    else:
        cursor.execute("SELECT * FROM prices WHERE product_name LIKE ?", ('%'+pname+'%',))
    rows = cursor.fetchall()
    print("[DEBUG] price-ranking rows:", rows)

    # 30â€¯km ä»¥å†…ãƒ•ã‚£ãƒ«ã‚¿ & ä¾¡æ ¼æ˜‡é †
    results = []
    for r in rows:
        id, p_name, price, shop, lat, lon, jan, img, created_at = r

        # ---------- ã“ã“ã‹ã‚‰ãƒ‡ãƒãƒƒã‚° ----------
        try:
            print(
                "[DEBUG] geodesic inputs:",
                f"lat0={lat0} ({type(lat0)})",
                f"lon0={lon0} ({type(lon0)})",
                f"lat={lat} ({type(lat)})",
                f"lon={lon} ({type(lon)})",
            )

            # å¿…è¦ãªã‚‰ float ã¸ã‚­ãƒ£ã‚¹ãƒˆã—ã¦ç¢ºèª
            lat0_f = float(lat0)
            lon0_f = float(lon0)
            lat_f  = float(lat)
            lon_f  = float(lon)

            # ç¯„å›²å¤–ãªã‚‰ã‚¹ã‚­ãƒƒãƒ—
            if not (-90 <= lat_f <= 90 and -180 <= lon_f <= 180):
                print("[WARN] ç·¯åº¦çµŒåº¦ãŒç¯„å›²å¤–ã®ãŸã‚ã‚¹ã‚­ãƒƒãƒ—:", lat_f, lon_f)
                continue

            # è·é›¢è¨ˆç®—
            dist = geodesic((lat0_f, lon0_f), (lat_f, lon_f)).kilometers
            print(f"è·é›¢è¨ˆç®—ï¼š{dist}")

        except ValueError as e:
            print("[ERROR] geodesic ValueError:", e)
            continue
        # ---------- ã“ã“ã¾ã§ãƒ‡ãƒãƒƒã‚° ----------
        if dist <= 2:
            results.append({
                "å•†å“å": p_name,
                "å•†å“ç”»åƒ": img,
                "åº—èˆ—å": shop,
                "ä¾¡æ ¼": price,
                "ç·¯åº¦": lat,
                "çµŒåº¦": lon,
                "è·é›¢_km": round(dist,2)
            })
    results.sort(key=lambda x: x["ä¾¡æ ¼"])
    print(f"ä¾¡æ ¼ã«ã‚ˆã‚‹ã‚½ãƒ¼ãƒˆï¼š{results}")
    return jsonify({"ranking": results[:5]})



if __name__ == '__main__':
    # é–‹ç™ºç”¨ï¼šãƒ­ãƒ¼ã‚«ãƒ«ç¢ºèªç”¨ã®Flaskã‚µãƒ¼ãƒãƒ¼
    # æ³¨æ„ï¼šæœ¬ç•ªã§ã¯ gunicorn ãªã© WSGI ã‚µãƒ¼ãƒãƒ¼ã‚’ä½¿ã£ã¦èµ·å‹•ã—ã¦ãã ã•ã„
    # ä¾‹: gunicorn -w 4 ocr_api_server:app
    app.run(host='0.0.0.0', port=8000, debug=True)

